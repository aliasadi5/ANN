{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Module\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "cqCHOayfl79U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'Preprocessed data/processed_results.csv'\n",
        "my_df = pd.read_csv(file)\n"
      ],
      "metadata": {
        "id": "Y_1p5fDLl8dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a model class that inherits nn.modules\n",
        "class Model(nn.Module):\n",
        "    #Input features(The number of object's feature)\n",
        "    #First hidden layer(The number of neurons in first layer)\n",
        "    #Second hidden layer(The number of neurons in second layer)\n",
        "    #Output(The number of classes in which depends on objects)\n",
        "    def __init__(self, in_features = 5, hidden1 = 12, hidden2 = 12, out_features = 2):\n",
        "        #To instantiate our nn.Module\n",
        "        super().__init__()\n",
        "        #To conect all neurons with eachother\n",
        "        self.fc1 = nn.Linear(in_features,hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1,hidden2)\n",
        "        self.out = nn.Linear(hidden2,out_features)\n",
        "        #A function which moves everthing forward\n",
        "    def forward(self,x):\n",
        "        #relu:>Rectified linear unit:>It is defined as h = max(0, a) where a is any real number.\n",
        "        #If a is less than or equal to 0, the function returns 0, otherwise, it returns a\n",
        "        #This function moves data from input to first hidden layer and then second and then output\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "j5FHPMBGl_FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pick a manual seed for randomization\n",
        "#Random number seeking\n",
        "torch.manual_seed(41)\n",
        "model = Model()\n",
        "\n",
        "file = 'Preprocessed data/processed_results.csv'\n",
        "my_df = pd.read_csv(file)"
      ],
      "metadata": {
        "id": "Z_BF7sSHmCnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split. set x,y\n",
        "x = my_df.drop('Output',axis=1)\n",
        "y = my_df['Output']\n",
        "#Convert these numpy arrays\n",
        "x = x.values\n",
        "y = y.values\n",
        "\n",
        "#Running train test split\n",
        "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size=0.3 , random_state = 45)# 70% is train and 30% is test\n",
        "\n",
        "#Convert x features to float tensors\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "\n",
        "#Convert y features to tensors long\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "#Set criterion of model to measure the error, how far off the predictions are from data\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#Choose an Adam optimizer , learning rate = if the error doesn't go down after a bunch of iterations(epochs), learning rate will decrease\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.008)\n"
      ],
      "metadata": {
        "id": "eUwSHC8qmFPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train our model\n",
        "#Epoch:> one run through all the training data in network\n",
        "epochs = 1900\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "\n",
        "    #Go through and make a prediction\n",
        "    y_pred = model.forward(x_train) #Getting the predicted results\n",
        "\n",
        "    #Measuring the loss which will be high at first\n",
        "    loss = criterion(y_pred,y_train) #Predicted values vs y_train\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    #Print every 10 epoch\n",
        "    if i % 10 == 0:\n",
        "        print(f\"'Epoch: {i} and loss: {loss}\")\n",
        "    #Do back propqgation:> take the error rate of forward propagation and feed it back though the network to fine tune weights\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "82bLJZFYmJkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epochs),losses)\n",
        "plt.ylabel(\"loss/error\")\n",
        "plt.xlabel(\"epoch\")"
      ],
      "metadata": {
        "id": "fqJxQMefmME9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model on test dataset(test validation)\n",
        "with torch.no_grad(): #Basically turn off back propogation\n",
        "    y_eval = model.forward(x_test) #x_test are features form test set and, y_eval will be our predictions\n",
        "    loss = criterion(y_eval,y_test) #Find the loss or error"
      ],
      "metadata": {
        "id": "HWPk-v7LmPmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "iI88NzXimUWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will tell us the nomber of correct predictions for test set.\n",
        "True_One = 0\n",
        "False_True = 0\n",
        "False_Zero = 0\n",
        "True_False = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(x_test)\n",
        "    predicted_classes = y_pred.argmax(dim=1)\n",
        "    cm = confusion_matrix(y_test, predicted_classes)\n",
        "        #print(f'{i+1}.)   {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    #    if predicted_class == 1 and  true_class == 1:\n",
        "           # True_One += 1\n",
        "\n",
        "     #   elif predicted_class == 0 and true_class == 0:\n",
        "          #  False_Zero += 1\n",
        "\n",
        "      #  elif predicted_class ==1 and true_class == 0:\n",
        "         #   False_True += 1\n",
        "\n",
        "       # else:\n",
        "        #    True_False += 1\n",
        "'''        precision = True_One / (True_One + False_True)\n",
        "        recall = True_One / (True_One + True_False)\n",
        "        F1_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "print(f'True:> {True_One}')\n",
        "print(f'False:> {False_Zero}')\n",
        "print(f'False_Pos:> {False_True}')\n",
        "print(f'False_Neg:> {True_False}')\n",
        "print(f'Precision:> {precision}')\n",
        "print(f'Recall:> {recall}')\n",
        "print(f'F1-score:> {F1_score}')'''\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3vyQhbAZmWve"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}